{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Csi task2 (Case 2).ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtip24b5MYZ3"
      },
      "source": [
        "!unzip v_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTZuuSxgUSio"
      },
      "source": [
        "from pathlib import Path\n",
        "import glob\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from keras import backend as K\n",
        "from keras.preprocessing.image import load_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "ozkDWqczTgGc",
        "outputId": "c4c6640a-b2b2-4e93-c830-08d65af8617e"
      },
      "source": [
        "train_data_dir = Path('v_data/test/planes')\n",
        "images = train_data_dir.glob(\"*.jpg\")\n",
        "train_data = []\n",
        "for image in images:\n",
        "  img=load_img(image, target_size=(227, 227))\n",
        "  img = np.array(img)\n",
        "  img = img / 255.0\n",
        "  img = img.reshape(1,227,227,3)\n",
        "  train_data.append([img,1])\n",
        "\n",
        "\n",
        "train_data_dir = Path('v_data/test/cars')\n",
        "images = train_data_dir.glob(\"*.jpg\")\n",
        "for image in images:\n",
        "  img=load_img(image, target_size=(227, 227))\n",
        "  img = np.array(img)\n",
        "  img = img / 255.0\n",
        "  img = img.reshape(1,227,227,3)\n",
        "  train_data.append([img,0])\n",
        "test_data = pd.DataFrame(train_data,columns=['image','label'],index = None)\n",
        "test_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[[[[0.47058824 0.59607843 0.65490196], [0.4666...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[[[[0.58431373 0.6627451  0.76862745], [0.5843...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[[[[0.46666667 0.63921569 0.81568627], [0.4666...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[[[[0.28235294 0.30980392 0.34117647], [0.5568...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[[[[0.41176471 0.44313725 0.4       ], [0.3098...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>[[[[0.69019608 0.60784314 0.15686275], [0.6901...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>[[[[0.62745098 0.65098039 0.70588235], [0.6274...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>[[[[0.29019608 0.3372549  0.4       ], [0.4745...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>[[[[0.91764706 0.91764706 0.90980392], [0.9137...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>[[[[1. 1. 1.], [1. 1. 1.], [1. 1. 1.], [1. 1. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                image  label\n",
              "0   [[[[0.47058824 0.59607843 0.65490196], [0.4666...      1\n",
              "1   [[[[0.58431373 0.6627451  0.76862745], [0.5843...      1\n",
              "2   [[[[0.46666667 0.63921569 0.81568627], [0.4666...      1\n",
              "3   [[[[0.28235294 0.30980392 0.34117647], [0.5568...      1\n",
              "4   [[[[0.41176471 0.44313725 0.4       ], [0.3098...      1\n",
              "..                                                ...    ...\n",
              "95  [[[[0.69019608 0.60784314 0.15686275], [0.6901...      0\n",
              "96  [[[[0.62745098 0.65098039 0.70588235], [0.6274...      0\n",
              "97  [[[[0.29019608 0.3372549  0.4       ], [0.4745...      0\n",
              "98  [[[[0.91764706 0.91764706 0.90980392], [0.9137...      0\n",
              "99  [[[[1. 1. 1.], [1. 1. 1.], [1. 1. 1.], [1. 1. ...      0\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xay4AM2gc0yh"
      },
      "source": [
        "train_data_dir = 'v_data/train'\n",
        "validation_data_dir = 'v_data/test'\n",
        "nb_train_samples =400\n",
        "nb_validation_samples = 100\n",
        "epochs = 10\n",
        "batch_size = 16\n",
        "img_width, img_height = 224, 224"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5NPs6TBWc_b7"
      },
      "source": [
        "if K.image_data_format() == 'channels_first':\n",
        "\tinput_shape = (3, img_width, img_height)\n",
        "else:\n",
        "\tinput_shape = (img_width, img_height, 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87_bXHsaeViA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4QxdH_imdCGm"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(32, (2, 2), input_shape=input_shape))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(32, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Conv2D(64, (2, 2)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1))\n",
        "model.add(Activation('sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bau1nzuKeOpv"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "\t\t\toptimizer='rmsprop',\n",
        "\t\t\tmetrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "id": "gnkW_FzZki5e",
        "outputId": "d5ec7af4-8a02-4dd1-b86d-24b62d58a165"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "\trescale=1. / 255,\n",
        "\tshear_range=0.2,\n",
        "\tzoom_range=0.2,\n",
        "\thorizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "\ttrain_data_dir,\n",
        "\ttarget_size=(img_width, img_height),\n",
        "\tbatch_size=batch_size,\n",
        "\tclass_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "\tvalidation_data_dir,\n",
        "\ttarget_size=(img_width, img_height),\n",
        "\tbatch_size=batch_size,\n",
        "\tclass_mode='binary')\n",
        "\n",
        "model.fit_generator(\n",
        "\ttrain_generator,\n",
        "\tsteps_per_epoch=nb_train_samples // batch_size,\n",
        "\tepochs=epochs,\n",
        "\tvalidation_data=validation_generator,\n",
        "\tvalidation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e400c965663a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \tclass_mode='binary')\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m validation_generator = test_datagen.flow_from_directory(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    990\u001b[0m         \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         interpolation=interpolation)\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m   def flow_from_dataframe(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 410\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'v_data/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6w8ms9Rkmt-"
      },
      "source": [
        "model_ann = Sequential()\n",
        "model_ann.add(Dense(16, input_shape=input_shape, activation='relu'))\n",
        "model_ann.add(Dropout(0.4))\n",
        "model_ann.add(Dense(32, activation='relu'))\n",
        "model_ann.add(Dropout(0.6))\n",
        "model_ann.add(Flatten())\n",
        "model_ann.add(Dense(64,input_shape=input_shape, activation='softmax'))\n",
        "model_ann.add(Dropout(0.2))\n",
        "model_ann.add(Dense(1))\n",
        "model_ann.add(Activation('sigmoid'))\n",
        "model_ann.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Q0roMB91BtN"
      },
      "source": [
        "\n",
        "model_ann.fit_generator(\n",
        "\ttrain_generator,\n",
        "\tsteps_per_epoch=nb_train_samples // batch_size,\n",
        "\tepochs=epochs,\n",
        "\tvalidation_data=validation_generator,\n",
        "\tvalidation_steps=nb_validation_samples // batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO4uyNjk-prd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34GFnch2-vjd"
      },
      "source": [
        "model_ann.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV51Og5M8YVt"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "image = load_img('v_data/test/cars/5.jpg', target_size=(227, 227))\n",
        "img = np.array(image)\n",
        "img = img / 255.0\n",
        "img = img.reshape(1,227,227,3)\n",
        "label = model_ann.predict(img)\n",
        "print(\"Predicted Class (0 - Cars , 1- Planes): \", np.argmax(label,axis=1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bqaRZt6UMDqp",
        "outputId": "0f51dc26-ff3d-4917-87f9-90b353942e55"
      },
      "source": [
        "type(test_data['image'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}